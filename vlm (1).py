# -*- coding: utf-8 -*-
"""vlm

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OHu79Ycvyy5eLfOt48Yo2ftT1aCZZBKh
"""

!pip install transformers accelerate safetensors torch torchvision

from transformers import AutoProcessor, LlavaForConditionalGeneration
import torch, gc
from PIL import Image
import requests

if torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"
print(f"Using device: {device}")

def recipe(user_img_path, user_input):
    model_id = "llava-hf/llava-1.5-7b-hf"
    model = LlavaForConditionalGeneration.from_pretrained(
        model_id,
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True,
    ).to(0)

    processor = AutoProcessor.from_pretrained(model_id)

    torch.cuda.empty_cache()
    gc.collect()


    image = Image.open(user_img_path).convert("RGB")






    conversation = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text":
                "You are a home-style chef. You will be shown a photo of a dish and a creatively described title.\n"
                  "Your task is to generate a simple 2–3 step recipe — just short cooking instructions, using common ingredients.\n"
                  "Keep your answer short and do not list ingredients separately — only include them within the steps.\n"
                  "Your output should be of similar tone, length and format as given in the following examples.\n\n"

                  "### Example 1:\n"
                  "Image: A burger\n"
                  "Dish title: bread stack\n"
                  "Output: Make the patty by mixing beef and bread crumbs. Form into 3/4 inch thick patties and grill them. Assemble the patties, bun, tomatoes, onions, lettuce and sauce. Serve.\n\n"


                  "### Example 2:\n"
                  "Image: A plate of fries\n"
                  "Dish title: golden sticks\n"
                  "Output: Peel the potatoes and cut them into thin sticks. Heat the oil in a frying pan and add the sliced potatoes. Sprinkle with salt. Serve.\n\n"


                  "###Example 3:\n"
                  "Image: donuts\n"
                  "Dish title: sweet ring things\n"
                  "Output: To make the dough, whisk egg, butter, sugar, baking powder, flour in a bowl. Cut out the donuts from the dough using a donut cutter. Fry them for 2–3 minutes. Cover them with sugar, icing, chocolate sauce and sprinkles.\n\n"


                  "Now here’s a new one:"
                },
                {"type": "image"},
                {"type": "text", "text": f"Dish title: {user_input}. What's the recipe?"}
            ],
        },
    ]


    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)


    inputs = processor(images=image, text=prompt, return_tensors='pt').to(0, torch.float16)



    with torch.no_grad():
            output = model.generate(**inputs, max_new_tokens=100)

    torch.cuda.empty_cache()
    gc.collect()


    response = processor.batch_decode(output[:, inputs["input_ids"].shape[-1]:], skip_special_tokens=True)[0]
    return(response)

import json

with open("/content/VLMdata/data.json", "r") as f:
  all_data = json.load(f)

results = []
for dish in all_data:
  user_img_path = dish["image"]
  user_input = dish["title"]
  print(f"\nDish title (vague): {user_input}")
  recipe_text = recipe(user_img_path, user_input)
  print(f"\nRecipe: {recipe_text}")

  results.append({
        "image_path": user_img_path,
        "dish_title": user_input,
        "generated_recipe": recipe_text
    })

with open("output.json", "w") as f:
    json.dump(results, f, indent=4)

print(results)

from google.colab import files

files.download("output.json")